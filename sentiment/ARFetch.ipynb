{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e1f35-080f-4d6d-ae8c-c615bf44c99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cookies extracted and session initialized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/179 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 360 ONE WAM Ltd., already processed\n",
      "Skipping AU Small Finance Bank Ltd., already processed\n",
      "Skipping Aadhar Housing Finance Ltd., already processed\n",
      "Skipping Aavas Financiers Ltd., already processed\n",
      "Skipping Aditya Birla Capital Ltd., already processed\n",
      "Skipping Aditya Birla Sun Life AMC Ltd., already processed\n",
      "Skipping Anand Rathi Wealth Ltd., already processed\n",
      "Skipping Angel One Ltd., already processed\n",
      "Skipping Aptus Value Housing Finance India Ltd., already processed\n",
      "Skipping Axis Bank Ltd., already processed\n",
      "Skipping BSE Ltd., already processed\n",
      "Skipping Bajaj Finance Ltd., already processed\n",
      "Skipping Bajaj Finserv Ltd., already processed\n",
      "Skipping Bajaj Holdings & Investment Ltd., already processed\n",
      "Skipping Bandhan Bank Ltd., already processed\n",
      "Skipping Bank of Baroda, already processed\n",
      "Skipping Bank of India, already processed\n",
      "Skipping Bank of Maharashtra, already processed\n",
      "Skipping CRISIL Ltd., already processed\n",
      "Skipping Can Fin Homes Ltd., already processed\n",
      "Skipping Canara Bank, already processed\n",
      "Skipping Capri Global Capital Ltd., already processed\n",
      "Skipping Central Bank of India, already processed\n",
      "Skipping Central Depository Services (India) Ltd., already processed\n",
      "Skipping Cholamandalam Financial Holdings Ltd., already processed\n",
      "Skipping Cholamandalam Investment and Finance Company Ltd., already processed\n",
      "Skipping City Union Bank Ltd., already processed\n",
      "Skipping Computer Age Management Services Ltd., already processed\n",
      "Skipping CreditAccess Grameen Ltd., already processed\n",
      "Skipping Equitas Small Finance Bank Ltd., already processed\n",
      "Skipping Affle (India) Ltd., already processed\n",
      "Skipping Birlasoft Ltd., already processed\n",
      "Skipping C.E. Info Systems Ltd., already processed\n",
      "Skipping Coforge Ltd., already processed\n",
      "Skipping Cyient Ltd., already processed\n",
      "Skipping HCL Technologies Ltd., already processed\n",
      "Skipping Happiest Minds Technologies Ltd., already processed\n",
      "Skipping Infosys Ltd., already processed\n",
      "Skipping Intellect Design Arena Ltd., already processed\n",
      "Skipping KPIT Technologies Ltd., already processed\n",
      "Skipping L&T Technology Services Ltd., already processed\n",
      "Skipping LTIMindtree Ltd., already processed\n",
      "Skipping Latent View Analytics Ltd., already processed\n",
      "Skipping Mastek Ltd., already processed\n",
      "Skipping MphasiS Ltd., already processed\n",
      "Skipping Netweb Technologies India Ltd., already processed\n",
      "Skipping Newgen Software Technologies Ltd., already processed\n",
      "Skipping Oracle Financial Services Software Ltd., already processed\n",
      "Skipping Persistent Systems Ltd., already processed\n",
      "Skipping Sonata Software Ltd., already processed\n",
      "Skipping Tanla Platforms Ltd., already processed\n",
      "Skipping Tata Consultancy Services Ltd., already processed\n",
      "Skipping Tata Elxsi Ltd., already processed\n",
      "Skipping Tata Technologies Ltd., already processed\n",
      "Skipping Tech Mahindra Ltd., already processed\n",
      "Skipping Abbott India Ltd., already processed\n",
      "Skipping Ajanta Pharmaceuticals Ltd., already processed\n",
      "Skipping Akums Drugs and Pharmaceuticals Ltd., already processed\n",
      "Skipping Alembic Pharmaceuticals Ltd., already processed\n",
      "Skipping Alkem Laboratories Ltd., already processed\n",
      "Skipping Apollo Hospitals Enterprise Ltd., already processed\n",
      "Skipping Aster DM Healthcare Ltd., already processed\n",
      "Skipping AstraZenca Pharma India Ltd., already processed\n",
      "Skipping Aurobindo Pharma Ltd., already processed\n",
      "Skipping Biocon Ltd., already processed\n",
      "Skipping Caplin Point Laboratories Ltd., already processed\n",
      "Skipping Cipla Ltd., already processed\n",
      "Skipping Concord Biotech Ltd., already processed\n",
      "Skipping Divi's Laboratories Ltd., already processed\n",
      "Skipping Dr. Lal Path Labs Ltd., already processed\n",
      "Skipping Dr. Reddy's Laboratories Ltd., already processed\n",
      "Skipping Emcure Pharmaceuticals Ltd., already processed\n",
      "Skipping Eris Lifesciences Ltd., already processed\n",
      "Skipping Fortis Healthcare Ltd., already processed\n",
      "Skipping Gland Pharma Ltd., already processed\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2023_2024.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2022_2023.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2022_2023.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2022_2023_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2021_2022.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2021_2022.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2021_2022_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2020_2021.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2020_2021.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2020_2021_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2019_2020.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2019_2020.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2019_2020_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2018_2019.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2018_2019.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2018_2019_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2017_2018.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2017_2018.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2017_2018_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2016_2017.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2016_2017.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2016_2017_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2015_2016.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2015_2016.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2015_2016_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2014_2015.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2014_2015.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2014_2015_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2013_2013.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2013_2013.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2013_2013_1.pdf\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2013_2013_2.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2012_2012.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2012_2012.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2012_2012_1.pdf\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2012_2012_2.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2011_2011.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2011_2011.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2011_2011_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2010_2010.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2010_2010.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2010_2010_1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▍                                              | 76/179 [01:58<02:40,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Downloaded and saved: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2009_2009.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2009_2009.pdf to nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glaxosmithkline_Pharmaceuticals_Ltd_AR\\Glaxosmithkline_Pharmaceuticals_Ltd_2009_2009_1.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glenmark_Pharmaceuticals_Ltd_AR\\Glenmark_Pharmaceuticals_Ltd_2023_2024.pdf\n",
      "✅ Downloaded and saved: nse_annual_reports\\Glenmark_Pharmaceuticals_Ltd_AR\\Glenmark_Pharmaceuticals_Ltd_2022_2023.pdf\n",
      "📂 Extracted: nse_annual_reports\\Glenmark_Pharmaceuticals_Ltd_AR\\Glenmark_Pharmaceuticals_Ltd_2022_2023.pdf to nse_annual_reports\\Glenmark_Pharmaceuticals_Ltd_AR\\extracted_reports\n",
      "📄 Renamed and saved PDF: nse_annual_reports\\Glenmark_Pharmaceuticals_Ltd_AR\\Glenmark_Pharmaceuticals_Ltd_2022_2023_1.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# --- User-Agent List ---\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\"\n",
    "]\n",
    "\n",
    "# --- Step 1: Launch Browser and Extract Cookies ---\n",
    "def get_nse_cookies():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--start-maximized\")  \n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    options.add_argument(f\"user-agent={random.choice(USER_AGENTS)}\")\n",
    "\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    nse_url = \"https://www.nseindia.com/companies-listing/corporate-filings-annual-reports\"\n",
    "    driver.get(nse_url)\n",
    "    \n",
    "    time.sleep(random.randint(3, 6))\n",
    "\n",
    "    driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(random.uniform(2, 5))\n",
    "\n",
    "    cookies = {cookie['name']: cookie['value'] for cookie in driver.get_cookies()}\n",
    "    \n",
    "    driver.quit()\n",
    "    return cookies\n",
    "\n",
    "# --- Step 2: Load Stock List ---\n",
    "df_stocks = pd.read_csv(\"../data/top_250_stocks.csv\")  \n",
    "\n",
    "BASE_FOLDER = \"nse_annual_reports\"\n",
    "os.makedirs(BASE_FOLDER, exist_ok=True)\n",
    "\n",
    "# --- Step 3: Create Session Using Extracted Cookies ---\n",
    "cookies = get_nse_cookies()\n",
    "\n",
    "session = requests.Session()\n",
    "for name, value in cookies.items():\n",
    "    session.cookies.set(name, value)\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"*/*\",\n",
    "    \"user-agent\": random.choice(USER_AGENTS),\n",
    "    \"referer\": \"https://www.nseindia.com/companies-listing/corporate-filings-annual-reports\",\n",
    "    \"sec-fetch-mode\": \"cors\",\n",
    "    \"sec-fetch-site\": \"same-origin\"\n",
    "}\n",
    "\n",
    "print(\"✅ Cookies extracted and session initialized successfully.\")\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def clean_filename(name, max_length=50):\n",
    "    \"\"\"Sanitize company names for filenames.\"\"\"\n",
    "    name = re.sub(r'[^\\w\\s-]', '', name)\n",
    "    name = name.strip().replace(\" \", \"_\")\n",
    "    return name[:max_length]\n",
    "\n",
    "def extract_year_from_filename(filename):\n",
    "    \"\"\"Extract the year from the filename using regex.\"\"\"\n",
    "    match = re.search(r'(\\d{4}_\\d{4})', filename)  \n",
    "    if match:\n",
    "        return match.group(1)\n",
    "\n",
    "    match = re.search(r'(\\d{4})', filename)  \n",
    "    return match.group(1) if match else \"Unknown_Year\"\n",
    "\n",
    "def safe_request(url, max_retries=5):\n",
    "    \"\"\"Retry requests with exponential backoff.\"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            response = session.get(url, headers=headers, timeout=15, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "            elif response.status_code in [403, 429]:\n",
    "                wait_time = 30 + (10 * attempt)\n",
    "                print(f\"⚠️ Server blocking requests. Waiting {wait_time}s before retrying...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"❌ Unexpected HTTP {response.status_code}. Retrying...\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"❌ Request failed: {e}. Retrying...\")\n",
    "\n",
    "        attempt += 1\n",
    "        time.sleep(2 ** attempt)\n",
    "\n",
    "    print(f\"❌ Failed after {max_retries} attempts.\")\n",
    "    return None\n",
    "\n",
    "# def download_and_process_report(company_name, report_url):\n",
    "#     \"\"\"Download, extract, and save each report before moving to the next.\"\"\"\n",
    "#     clean_company_name = clean_filename(company_name)\n",
    "#     folder_path = os.path.join(BASE_FOLDER, f\"{clean_company_name}_AR\")\n",
    "#     os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "#     filename = report_url.split(\"/\")[-1]\n",
    "    # financial_year = extract_year_from_filename(filename)\n",
    "    # base_filename = clean_filename(filename.split(\"_\")[0], max_length=20)\n",
    "\n",
    "    # unique_filename = f\"{clean_company_name}_{financial_year}.pdf\"\n",
    "    # file_path = os.path.join(folder_path, unique_filename)\n",
    "\n",
    "    # response = safe_request(report_url)\n",
    "    # if response:\n",
    "    #     with open(file_path, \"wb\") as file:\n",
    "    #         for chunk in response.iter_content(chunk_size=1024):\n",
    "    #             file.write(chunk)\n",
    "    #     print(f\"✅ Downloaded and saved: {file_path}\")\n",
    "\n",
    "    #     if filename.endswith(\".zip\"):\n",
    "    #         try:\n",
    "    #             with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    #                 zip_ref.extractall(folder_path)\n",
    "    #             print(f\"📂 Extracted: {file_path} to {folder_path}\")\n",
    "\n",
    "    #             for file in os.listdir(folder_path):\n",
    "    #                 if file.endswith(\".pdf\"):\n",
    "    #                     extracted_pdf_path = os.path.join(folder_path, file)\n",
    "\n",
    "    #                     extracted_year = extract_year_from_filename(file)\n",
    "    #                     if extracted_year == \"Unknown_Year\":\n",
    "    #                         extracted_year = financial_year  \n",
    "\n",
    "    #                     new_pdf_path = os.path.join(folder_path, f\"{clean_company_name}_{extracted_year}.pdf\")\n",
    "\n",
    "    #                     counter = 1\n",
    "    #                     while os.path.exists(new_pdf_path):\n",
    "    #                         new_pdf_path = os.path.join(folder_path, f\"{clean_company_name}_{extracted_year}_{counter}.pdf\")\n",
    "    #                         counter += 1\n",
    "\n",
    "    #                     os.rename(extracted_pdf_path, new_pdf_path)\n",
    "    #                     print(f\"📄 Renamed PDF: {new_pdf_path}\")\n",
    "\n",
    "    #             os.remove(file_path)\n",
    "\n",
    "    #         except zipfile.BadZipFile:\n",
    "    #             print(f\"❌ Corrupted ZIP file: {file_path}\")\n",
    "\n",
    "    # else:\n",
    "    #     print(f\"❌ Failed to download: {report_url}\")\n",
    "def download_and_process_report(company_name, report_url):\n",
    "    \"\"\"Download, extract, and save each report before moving to the next.\"\"\"\n",
    "    clean_company_name = clean_filename(company_name)\n",
    "    folder_path = os.path.join(BASE_FOLDER, f\"{clean_company_name}_AR\")\n",
    "    extracted_folder = os.path.join(folder_path, \"extracted_reports\")  # Separate folder for extraction\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    os.makedirs(extracted_folder, exist_ok=True)\n",
    "\n",
    "    filename = report_url.split(\"/\")[-1]\n",
    "    financial_year = extract_year_from_filename(filename)\n",
    "    base_filename = clean_filename(filename.split(\"_\")[0], max_length=20)\n",
    "\n",
    "    # Ensure the original downloaded file is not overwritten\n",
    "    unique_filename = f\"{clean_company_name}_{financial_year}.pdf\"\n",
    "    file_path = os.path.join(folder_path, unique_filename)\n",
    "\n",
    "    response = safe_request(report_url)\n",
    "    if response:\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"✅ Downloaded and saved: {file_path}\")\n",
    "\n",
    "        # Handle ZIP extraction (if applicable)\n",
    "        if filename.endswith(\".zip\"):\n",
    "            try:\n",
    "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(extracted_folder)  # Extract into a separate subfolder\n",
    "                print(f\"📂 Extracted: {file_path} to {extracted_folder}\")\n",
    "\n",
    "                for file in os.listdir(extracted_folder):\n",
    "                    if file.endswith(\".pdf\"):\n",
    "                        extracted_pdf_path = os.path.join(extracted_folder, file)\n",
    "\n",
    "                        # Extract actual year from each PDF\n",
    "                        extracted_year = extract_year_from_filename(file)\n",
    "                        if extracted_year == \"Unknown_Year\":\n",
    "                            extracted_year = financial_year  \n",
    "\n",
    "                        new_pdf_path = os.path.join(folder_path, f\"{clean_company_name}_{extracted_year}.pdf\")\n",
    "\n",
    "                        # Ensure unique filename if multiple reports exist\n",
    "                        counter = 1\n",
    "                        while os.path.exists(new_pdf_path):\n",
    "                            new_pdf_path = os.path.join(folder_path, f\"{clean_company_name}_{extracted_year}_{counter}.pdf\")\n",
    "                            counter += 1\n",
    "\n",
    "                        os.rename(extracted_pdf_path, new_pdf_path)\n",
    "                        print(f\"📄 Renamed and saved PDF: {new_pdf_path}\")\n",
    "\n",
    "                os.remove(file_path)  # Delete ZIP only after all extractions are done\n",
    "\n",
    "            except zipfile.BadZipFile:\n",
    "                print(f\"❌ Corrupted ZIP file: {file_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"❌ Failed to download: {report_url}\")\n",
    "\n",
    "def fetch_nse_reports(symbol, company_name):\n",
    "    \"\"\"Fetch reports and process one by one (download, save, move to next).\"\"\"\n",
    "    encoded_company_name = company_name.replace(\" \", \"%20\")\n",
    "    nse_api_url = f\"https://www.nseindia.com/api/annual-reports?index=equities&symbol={symbol}&issuer={encoded_company_name}\"\n",
    "\n",
    "    response = safe_request(nse_api_url)\n",
    "\n",
    "    if response:\n",
    "        try:\n",
    "            data = response.json()\n",
    "            reports = data.get(\"data\", [])\n",
    "\n",
    "            if reports:\n",
    "                for report in reports:\n",
    "                    report_url = report[\"fileName\"]\n",
    "                    \n",
    "                    download_and_process_report(company_name, report_url)\n",
    "            else:\n",
    "                print(f\"⚠️ No reports found for {company_name} ({symbol})\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"❌ Error parsing JSON response for {company_name} ({symbol})\")\n",
    "\n",
    "    else:\n",
    "        print(f\"❌ Failed to fetch reports for {company_name} ({symbol})\")\n",
    "\n",
    "PROGRESS_FILE = \"./progress.txt\"\n",
    "completed_companies = set()\n",
    "if os.path.exists(PROGRESS_FILE):\n",
    "    with open(PROGRESS_FILE, \"r\") as f:\n",
    "        completed_companies = set(line.strip() for line in f.readlines())\n",
    "\n",
    "for _, row in tqdm(df_stocks.iterrows(), total=len(df_stocks)):\n",
    "    company_name = row[\"Company Name\"]\n",
    "    symbol = row[\"Symbol\"]\n",
    "    if company_name in completed_companies:\n",
    "        print(f\"Skipping {company_name}, already processed\")\n",
    "        continue\n",
    "    try:\n",
    "        fetch_nse_reports(symbol, company_name)\n",
    "        with open(PROGRESS_FILE, \"a\") as f:\n",
    "            f.write(company_name + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping {company_name} due to error: {e}\")\n",
    "\n",
    "print(\"\\n✅ All reports downloaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd1497-7ea9-45e7-aca6-02d5b8c53f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
